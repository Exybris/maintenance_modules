"""
metrics.py - Calcul des m√©triques FPS
Version exhaustive conforme √† la feuille de route FPS V1.3
---------------------------------------------------------------
NOTE FPS ‚Äì Plasticit√© m√©thodologique :
Les m√©triques (effort, entropy, etc.) sont ajustables : toute
modification ou alternative test√©e doit √™tre document√©e et laiss√©e
ouverte dans la config.
---------------------------------------------------------------

Ce module quantifie tous les aspects du syst√®me FPS :
- Performance computationnelle (CPU, m√©moire)
- Effort d'adaptation (interne, transitoire, chronique)
- Qualit√© dynamique (fluidit√©, stabilit√©, innovation)
- R√©silience et r√©gulation
- D√©tection d'√©tats (stable, transitoire, chronique, chaotique)

Les m√©triques sont le miroir empirique du syst√®me, permettant
la falsification et le raffinement continu.

(c) 2025 Gepetto & Andr√©a Gadal & Claude üåÄ
"""

import numpy as np
from scipy import signal
import time
import csv
import h5py
import os
from typing import Dict, List, Union, Optional, Tuple, Any
import warnings


# ============== M√âTRIQUES DE PERFORMANCE ==============

def compute_cpu_step(start_time: float, end_time: float, N: int) -> float:
    """
    Calcule le temps CPU normalis√© par pas et par strate.
    
    cpu_step = (end_time - start_time) / N
    
    Args:
        start_time: temps d√©but (time.perf_counter())
        end_time: temps fin
        N: nombre de strates
    
    Returns:
        float: temps CPU moyen par strate en secondes
    """
    if N <= 0:
        return 0.0
    return (end_time - start_time) / N


# ============== M√âTRIQUES D'EFFORT ==============

def compute_effort(delta_An_array: np.ndarray, delta_fn_array: np.ndarray, 
                   delta_gamma_n_array: np.ndarray, An_max: float, fn_max: float, 
                   gamma_max: float) -> float:
    """
    Calcule l'effort d'adaptation interne du syst√®me.
    
    Version normalis√©e pour coh√©rence dimensionnelle :
    effort = Œ£‚Çô [|ŒîA‚Çô|/An_max + |Œîf‚Çô|/fn_max + |ŒîŒ≥‚Çô|/gamma_max]
    
    Args:
        delta_An_array: variations d'amplitude
        delta_fn_array: variations de fr√©quence
        delta_gamma_n_array: variations de latence
        An_max: amplitude maximale (pour normalisation)
        fn_max: fr√©quence maximale
        gamma_max: latence maximale
    
    Returns:
        float: effort total normalis√©
    
    Note:
        L'effort mesure l'intensit√© des ajustements internes.
        Un effort √©lev√© indique que le syst√®me "travaille" beaucoup.
    """
    effort = 0.0
    
    # Protection contre division par z√©ro
    if An_max > 0:
        effort += np.sum(np.abs(delta_An_array)) / An_max
    if fn_max > 0:
        effort += np.sum(np.abs(delta_fn_array)) / fn_max
    if gamma_max > 0:
        effort += np.sum(np.abs(delta_gamma_n_array)) / gamma_max
    
    return effort


def compute_effort_status(effort_t: float, effort_history: List[float], 
                          config: Dict) -> str:
    """
    D√©termine le statut de l'effort : stable, transitoire ou chronique.
    
    Args:
        effort_t: effort actuel
        effort_history: historique des efforts
        config: configuration (seuils)
    
    Returns:
        str: "stable", "transitoire" ou "chronique"
    
    Logique:
        - stable: effort dans la norme
        - transitoire: pic temporaire (adaptation ponctuelle)
        - chronique: effort √©lev√© persistant (syst√®me en lutte)
    """
    if len(effort_history) < 10:
        # Pas assez d'historique - on consid√®re stable par d√©faut
        return "stable"
    
    # Calcul des statistiques sur les 10 derniers pas
    recent_efforts = effort_history[-10:]
    mean_recent = np.mean(recent_efforts)
    
    # Seuils adaptatifs bas√©s sur l'historique complet
    if len(effort_history) >= 50:
        # Moyenne et √©cart-type sur une fen√™tre plus large
        long_term = effort_history[-50:]
        mean_long = np.mean(long_term)
        std_long = np.std(long_term)
        
        # D√©tection transitoire : pic > 2œÉ
        if effort_t > mean_long + 2 * std_long:
            return "transitoire"
        
        # D√©tection chronique : moyenne r√©cente √©lev√©e
        if mean_recent > mean_long + std_long:
            # V√©rifier la persistance
            high_count = sum(1 for e in recent_efforts if e > mean_long + std_long)
            if high_count >= 7:  # 70% du temps r√©cent
                return "chronique"
    
    # Sinon, utiliser des seuils fixes depuis config
    thresholds = config.get('to_calibrate', {})
    
    # Seuil transitoire
    if effort_t > thresholds.get('effort_transitoire_threshold', 2.0):
        return "transitoire"
    
    # Seuil chronique sur la moyenne
    if mean_recent > thresholds.get('effort_chronique_threshold', 1.5):
        return "chronique"
    
    return "stable"


def compute_mean_high_effort(effort_history: List[float], percentile: int = 80) -> float:
    """
    Calcule la moyenne haute de l'effort (percentile √©lev√©).
    
    Mesure l'effort chronique en regardant les valeurs hautes.
    
    Args:
        effort_history: historique complet des efforts
        percentile: percentile √† consid√©rer (80 par d√©faut)
    
    Returns:
        float: moyenne des efforts au-dessus du percentile
    """
    if len(effort_history) == 0:
        return 0.0
    
    if len(effort_history) < 10:
        # Pas assez de donn√©es - retourner la moyenne simple
        return np.mean(effort_history)
    
    # Calculer le seuil du percentile
    threshold = np.percentile(effort_history, percentile)
    
    # Moyenner les valeurs au-dessus
    high_efforts = [e for e in effort_history if e >= threshold]
    
    if len(high_efforts) == 0:
        return threshold
    
    return np.mean(high_efforts)


def compute_d_effort_dt(effort_history: List[float], dt: float) -> float:
    """
    Calcule la d√©riv√©e temporelle de l'effort.
    
    Mesure les variations brusques d'effort (transitoires).
    
    Args:
        effort_history: historique des efforts
        dt: pas de temps
    
    Returns:
        float: d√©riv√©e d_effort/dt
    """
    if len(effort_history) < 2:
        return 0.0
    
    # D√©riv√©e simple entre les deux derniers points
    return (effort_history[-1] - effort_history[-2]) / dt


# ============== M√âTRIQUES DE QUALIT√â DYNAMIQUE ==============

def compute_variance_d2S(S_history: List[float], dt: float) -> float:
    """
    Calcule la variance de la d√©riv√©e seconde de S(t).
    
    Mesure la fluidit√© : une faible variance indique des transitions douces.
    
    Args:
        S_history: historique du signal global
        dt: pas de temps
    
    Returns:
        float: variance de d¬≤S/dt¬≤
    """
    if len(S_history) < 3:
        return 0.0
    
    # Conversion en array pour calculs
    S_array = np.array(S_history)
    
    # Premi√®re d√©riv√©e
    dS_dt = np.gradient(S_array, dt)
    
    # Seconde d√©riv√©e
    d2S_dt2 = np.gradient(dS_dt, dt)
    
    # Variance
    return np.var(d2S_dt2)


def compute_entropy_S(S_t: Union[float, List[float], np.ndarray], 
                      sampling_rate: float) -> float:
    """
    Calcule l'entropie spectrale du signal S(t).
    
    Mesure l'innovation : haute entropie = riche en fr√©quences diverses.
    Utilise l'entropie de Shannon sur le spectre de puissance normalis√©.
    
    Args:
        S_t: signal (peut √™tre juste la valeur actuelle ou une fen√™tre)
        sampling_rate: fr√©quence d'√©chantillonnage (1/dt)
    
    Returns:
        float: entropie spectrale entre 0 et 1
    """
    # Si on n'a qu'une valeur, pas d'entropie spectrale possible
    if np.isscalar(S_t) or len(S_t) < 10:
        return 0.5  # Valeur par d√©faut "neutre"
    
    try:
        # Calcul du spectre de puissance
        freqs, psd = signal.periodogram(S_t, sampling_rate)
        
        # Normalisation pour obtenir une distribution de probabilit√©
        psd_norm = psd / np.sum(psd)
        
        # √âviter log(0)
        psd_norm = psd_norm + 1e-15
        
        # Entropie de Shannon
        entropy = -np.sum(psd_norm * np.log(psd_norm))
        
        # Normalisation par l'entropie maximale
        max_entropy = np.log(len(psd_norm))
        if max_entropy > 0:
            entropy_normalized = entropy / max_entropy
        else:
            entropy_normalized = 0.5
        
        return np.clip(entropy_normalized, 0.0, 1.0)
        
    except Exception as e:
        warnings.warn(f"Erreur dans compute_entropy_S: {e}")
        return 0.5


def compute_max_median_ratio(S_history: List[float]) -> float:
    """
    Calcule le ratio max/m√©diane du signal.
    
    Mesure la stabilit√© : un ratio √©lev√© indique des pics extr√™mes.
    
    Args:
        S_history: historique du signal
    
    Returns:
        float: ratio max(|S|) / median(|S|)
    """
    if len(S_history) < 10:
        return 1.0
    
    # Valeurs absolues
    S_abs = np.abs(S_history)
    
    # Protection contre m√©diane nulle
    median_val = np.median(S_abs)
    if median_val < 1e-10:
        median_val = 1e-10
    
    return np.max(S_abs) / median_val


# ============== M√âTRIQUES DE R√âGULATION ==============

def compute_mean_abs_error(En_array: np.ndarray, On_array: np.ndarray) -> float:
    """
    Calcule l'erreur absolue moyenne entre attendu et observ√©.
    
    mean(|E‚Çô(t) - O‚Çô(t)|)
    
    Mesure la qualit√© de la r√©gulation : faible = bonne convergence.
    
    Args:
        En_array: sorties attendues
        On_array: sorties observ√©es
    
    Returns:
        float: erreur absolue moyenne
    """
    if len(En_array) == 0 or len(On_array) == 0:
        return 0.0
    
    return np.mean(np.abs(En_array - On_array))


# ============== M√âTRIQUES DE R√âSILIENCE ==============

def compute_t_retour(S_history: List[float], t_choc: int, dt: float, 
                     threshold: float = 0.95) -> float:
    """
    Calcule le temps de retour √† l'√©quilibre apr√®s perturbation.
    
    Temps pour revenir √† 95% de l'√©tat pr√©-choc.
    
    Args:
        S_history: historique du signal
        t_choc: indice temporel du choc
        dt: pas de temps
        threshold: seuil de retour (0.95 = 95%)
    
    Returns:
        float: temps de retour en unit√©s de temps
    
    Note:
        √âtat pr√©-choc = moyenne de |S(t)| sur fen√™tre [t_choc-10*dt, t_choc]
    """
    if t_choc >= len(S_history) or t_choc < 10:
        return 0.0
    
    # √âtat pr√©-choc : moyenne sur EXACTEMENT 10 pas avant le choc
    pre_shock_window = S_history[max(0, t_choc-10):t_choc]
    if len(pre_shock_window) == 0:
        return 0.0
    
    etat_pre_choc = np.mean(np.abs(pre_shock_window))
    
    # Chercher quand |S(t)| revient √† ¬±5% de l'√©tat pr√©-choc
    tolerance = (1 - threshold) * etat_pre_choc
    
    for i in range(t_choc + 1, len(S_history)):
        # Valeur instantan√©e, pas de moyenne glissante
        current_value = abs(S_history[i])
        
        # V√©rifier si on est revenu dans la tol√©rance
        if abs(current_value - etat_pre_choc) <= tolerance:
            return (i - t_choc) * dt
    
    # Pas encore revenu √† l'√©quilibre
    return (len(S_history) - t_choc) * dt


# ============== V√âRIFICATION DES SEUILS ==============

def check_thresholds(metrics_dict: Dict[str, float], 
                     thresholds_dict: Dict[str, float]) -> Dict[str, bool]:
    """
    V√©rifie le franchissement des seuils pour chaque m√©trique.
    
    Args:
        metrics_dict: dictionnaire des m√©triques calcul√©es
        thresholds_dict: dictionnaire des seuils (depuis config)
    
    Returns:
        Dict[str, bool]: m√©trique -> d√©passement True/False
    
    Note:
        Seuils initiaux th√©oriques, √† ajuster apr√®s 5 runs de calibration
    """
    results = {}
    
    # Mapping des m√©triques aux seuils et conditions
    threshold_checks = {
        'variance_d2S': ('variance_d2S', lambda x, t: x > t),
        'max_median_ratio': ('stability_ratio', lambda x, t: x > t),
        't_retour': ('resilience', lambda x, t: x > t),
        'entropy_S': ('entropy_S', lambda x, t: x < t),
        'mean_high_effort': ('mean_high_effort', lambda x, t: x > t),
        'd_effort_dt': ('d_effort_dt', lambda x, t: x > t),
        'mean_abs_error': ('regulation_threshold', lambda x, t: x > t)
    }
    
    for metric_name, (threshold_key, check_func) in threshold_checks.items():
        if metric_name in metrics_dict and threshold_key in thresholds_dict:
            value = metrics_dict[metric_name]
            threshold = thresholds_dict[threshold_key]
            results[metric_name] = check_func(value, threshold)
        else:
            results[metric_name] = False
    
    return results


# ============== EXPORT ET LOGGING ==============

def log_metrics(t: float, metrics_dict: Dict[str, Any], csv_writer: Any, 
                hdf5_file: Optional[h5py.File] = None) -> None:
    """
    Exporte les m√©triques dans les fichiers de log.
    
    Args:
        t: temps actuel
        metrics_dict: toutes les m√©triques √† logger
        csv_writer: writer CSV (depuis simulate.py)
        hdf5_file: fichier HDF5 optionnel pour gros volumes
    
    Note:
        L'ordre des colonnes est d√©fini dans config['system']['logging']['log_metrics']
    """
    # Pour CSV : on suppose que simulate.py g√®re d√©j√† l'√©criture
    # Cette fonction est un placeholder pour extensions futures
    
    # Si HDF5 est fourni (pour N > 10 ou T > 1000)
    if hdf5_file is not None:
        try:
            # Cr√©er un groupe pour ce pas de temps
            time_group = hdf5_file.create_group(f"t_{int(t*1000)}")
            
            # Sauvegarder chaque m√©trique
            for key, value in metrics_dict.items():
                if isinstance(value, (int, float)):
                    time_group.attrs[key] = value
                elif isinstance(value, np.ndarray):
                    time_group.create_dataset(key, data=value)
                elif isinstance(value, str):
                    time_group.attrs[key] = value
                    
        except Exception as e:
            warnings.warn(f"Erreur HDF5 √† t={t}: {e}")


def summarize_metrics(metrics_history: Union[Dict[str, List], List[Dict]]) -> Dict[str, float]:
    """
    Calcule un r√©sum√© statistique des m√©triques sur tout le run.
    
    Args:
        metrics_history: historique complet des m√©triques
    
    Returns:
        Dict[str, float]: statistiques r√©sum√©es
    """
    summary = {}
    
    # Convertir en format uniforme si n√©cessaire
    if isinstance(metrics_history, list) and len(metrics_history) > 0:
        # Liste de dicts -> dict de listes
        keys = metrics_history[0].keys()
        history_dict = {k: [m.get(k, 0) for m in metrics_history] for k in keys}
    else:
        history_dict = metrics_history
    
    # Calculer les statistiques pour chaque m√©trique num√©rique
    for key, values in history_dict.items():
        if len(values) > 0 and isinstance(values[0], (int, float)):
            summary[f"{key}_mean"] = np.mean(values)
            summary[f"{key}_std"] = np.std(values)
            summary[f"{key}_min"] = np.min(values)
            summary[f"{key}_max"] = np.max(values)
            summary[f"{key}_final"] = values[-1]
    
    return summary


# ============== FONCTIONS SP√âCIALIS√âES ==============

def detect_chaos_events(S_history: List[float], threshold_sigma: float = 3.0) -> List[Dict]:
    """
    D√©tecte les √©v√©nements chaotiques dans le signal.
    
    Un √©v√©nement chaotique est d√©fini comme une d√©viation > threshold_sigma * œÉ.
    
    Args:
        S_history: historique du signal
        threshold_sigma: seuil en nombre d'√©carts-types
    
    Returns:
        List[Dict]: liste des √©v√©nements d√©tect√©s
    """
    if len(S_history) < 100:
        return []
    
    events = []
    S_array = np.array(S_history)
    
    # Statistiques de r√©f√©rence sur une fen√™tre glissante
    window_size = 50
    
    for i in range(window_size, len(S_array)):
        # Fen√™tre de r√©f√©rence
        window = S_array[i-window_size:i]
        mean_window = np.mean(window)
        std_window = np.std(window)
        
        # V√©rifier la valeur actuelle
        if std_window > 0:
            z_score = abs(S_array[i] - mean_window) / std_window
            
            if z_score > threshold_sigma:
                events.append({
                    'time_index': i,
                    'value': S_array[i],
                    'z_score': z_score,
                    'type': 'chaos'
                })
    
    return events


def compute_correlation_effort_cpu(effort_history: List[float], 
                                   cpu_history: List[float]) -> float:
    """
    Calcule la corr√©lation entre l'effort et le co√ªt CPU.
    
    Permet de d√©tecter si l'effort interne se traduit en charge computationnelle.
    
    Args:
        effort_history: historique des efforts
        cpu_history: historique des temps CPU
    
    Returns:
        float: coefficient de corr√©lation [-1, 1]
    """
    if len(effort_history) < 10 or len(cpu_history) < 10:
        return 0.0
    
    # Aligner les longueurs
    min_len = min(len(effort_history), len(cpu_history))
    effort_aligned = effort_history[-min_len:]
    cpu_aligned = cpu_history[-min_len:]
    
    # Corr√©lation de Pearson
    correlation_matrix = np.corrcoef(effort_aligned, cpu_aligned)
    
    if correlation_matrix.shape == (2, 2):
        return correlation_matrix[0, 1]
    else:
        return 0.0


# ============== TESTS ET VALIDATION ==============

if __name__ == "__main__":
    """
    Tests du module metrics.py
    """
    print("=== Tests du module metrics.py ===\n")
    
    # Test 1: CPU step
    print("Test 1 - CPU step:")
    start = time.perf_counter()
    time.sleep(0.1)  # Simuler du travail
    end = time.perf_counter()
    cpu = compute_cpu_step(start, end, 10)
    print(f"  CPU par strate: {cpu:.4f} secondes")
    
    # Test 2: Effort
    print("\nTest 2 - Effort:")
    delta_A = np.array([0.1, -0.05, 0.02])
    delta_f = np.array([0.01, 0.02, -0.01])
    delta_gamma = np.array([0.0, 0.0, 0.0])
    effort = compute_effort(delta_A, delta_f, delta_gamma, 1.0, 1.0, 1.0)
    print(f"  Effort total: {effort:.4f}")
    
    # Test 3: Variance d¬≤S/dt¬≤
    print("\nTest 3 - Fluidit√©:")
    # Signal sinuso√Ødal lisse
    t = np.linspace(0, 10, 100)
    S_smooth = np.sin(t)
    S_noisy = np.sin(t) + 0.1 * np.random.randn(100)
    
    var_smooth = compute_variance_d2S(S_smooth.tolist(), 0.1)
    var_noisy = compute_variance_d2S(S_noisy.tolist(), 0.1)
    print(f"  Variance lisse: {var_smooth:.6f}")
    print(f"  Variance bruit√©e: {var_noisy:.6f}")
    
    # Test 4: Entropie spectrale
    print("\nTest 4 - Entropie spectrale:")
    # Signal mono-fr√©quence vs multi-fr√©quence
    S_mono = np.sin(2 * np.pi * t)
    S_multi = np.sin(2 * np.pi * t) + 0.5 * np.sin(6 * np.pi * t) + 0.3 * np.sin(10 * np.pi * t)
    
    entropy_mono = compute_entropy_S(S_mono, 10.0)
    entropy_multi = compute_entropy_S(S_multi, 10.0)
    print(f"  Entropie mono-fr√©quence: {entropy_mono:.4f}")
    print(f"  Entropie multi-fr√©quence: {entropy_multi:.4f}")
    
    # Test 5: Temps de retour
    print("\nTest 5 - R√©silience:")
    # Signal avec perturbation
    S_perturbed = np.ones(100)
    S_perturbed[50:55] = 5.0  # Perturbation
    S_perturbed[55:] = 1.0 + 0.1 * np.exp(-0.1 * np.arange(45))  # Retour progressif
    
    t_ret = compute_t_retour(S_perturbed.tolist(), 50, 0.1, 0.95)
    print(f"  Temps de retour: {t_ret:.2f}")
    
    # Test 6: V√©rification des seuils
    print("\nTest 6 - V√©rification seuils:")
    metrics = {
        'variance_d2S': 0.02,
        'entropy_S': 0.3,
        'mean_high_effort': 2.5
    }
    thresholds = {
        'variance_d2S': 0.01,
        'entropy_S': 0.5,
        'mean_high_effort': 2.0
    }
    
    checks = check_thresholds(metrics, thresholds)
    for metric, exceeded in checks.items():
        print(f"  {metric}: {'D√âPASS√â' if exceeded else 'OK'}")
    
    print("\n‚úÖ Module metrics.py pr√™t pour quantifier l'harmonie!")
