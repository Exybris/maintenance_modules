"""
utils.py - Fonctions utilitaires pour le syst√®me FPS
Version compl√®te conforme √† la feuille de route FPS V1.3
---------------------------------------------------------------
Ce module contient toutes les fonctions transversales qui
facilitent l'orchestration du syst√®me FPS :

- Gestion des logs et fusion de donn√©es
- Sauvegarde et restauration d'√©tats
- Ex√©cution parall√®le de runs
- Exports en formats multiples
- G√©n√©ration d'identifiants uniques
- Gestion de la structure des dossiers

Chaque fonction est con√ßue pour la robustesse, la tra√ßabilit√©
et la facilit√© d'utilisation dans l'√©cosyst√®me FPS.

(c) 2025 Gepetto & Andr√©a Gadal & Claude (Anthropic) üåÄ
"""

import os
import csv
import json
import pickle
import hashlib
import shutil
import glob
from datetime import datetime
from typing import Dict, List, Union, Optional, Any, Tuple
import numpy as np
import pandas as pd
from multiprocessing import Pool, cpu_count
import warnings
import traceback

# Import optionnel pour HDF5
try:
    import h5py
    HDF5_AVAILABLE = True
except ImportError:
    HDF5_AVAILABLE = False
    warnings.warn("h5py non disponible - fonctionnalit√©s HDF5 d√©sactiv√©es")


# ============== GESTION DES LOGS ==============

def merge_logs(log_files: List[str], output_path: str, 
               format: str = 'csv') -> str:
    """
    Fusionne plusieurs fichiers de logs CSV en un seul.
    
    Args:
        log_files: liste des chemins vers les fichiers CSV
        output_path: chemin de sortie
        format: format de sortie ('csv' ou 'parquet')
    
    Returns:
        str: chemin du fichier fusionn√©
    """
    print(f"üîÑ Fusion de {len(log_files)} fichiers de logs...")
    
    # Charger tous les DataFrames
    dfs = []
    for log_file in log_files:
        try:
            df = pd.read_csv(log_file)
            # Ajouter une colonne avec le nom du fichier source
            df['source_file'] = os.path.basename(log_file)
            dfs.append(df)
            print(f"  ‚úì Charg√©: {os.path.basename(log_file)} ({len(df)} lignes)")
        except Exception as e:
            print(f"  ‚úó Erreur avec {log_file}: {e}")
    
    if not dfs:
        raise ValueError("Aucun fichier de log valide trouv√©")
    
    # Fusionner
    merged_df = pd.concat(dfs, ignore_index=True)
    
    # Trier par temps si la colonne existe
    if 't' in merged_df.columns:
        merged_df = merged_df.sort_values('t')
    
    # Sauvegarder
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else ".", 
                exist_ok=True)
    
    if format == 'csv':
        merged_df.to_csv(output_path, index=False)
    elif format == 'parquet' and 'pyarrow' in pd.io.parquet.get_engine('auto'):
        merged_df.to_parquet(output_path, index=False)
    else:
        # Fallback sur CSV
        output_path = output_path.replace('.parquet', '.csv')
        merged_df.to_csv(output_path, index=False)
    
    print(f"‚úÖ Fusion termin√©e: {output_path} ({len(merged_df)} lignes totales)")
    return output_path


def log_seed(seed: int, seed_file: str = "seeds.txt") -> None:
    """
    Enregistre une seed utilis√©e avec timestamp.
    
    Args:
        seed: valeur de la seed
        seed_file: fichier de log des seeds
    """
    os.makedirs(os.path.dirname(seed_file) if os.path.dirname(seed_file) else ".", 
                exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(seed_file, 'a') as f:
        f.write(f"{timestamp} | SEED = {seed}\n")


def log_config_and_meta(config: Dict, run_id: str, 
                        output_dir: str = "logs") -> None:
    """
    Sauvegarde la configuration et les m√©tadonn√©es d'un run.
    
    Args:
        config: configuration compl√®te
        run_id: identifiant du run
        output_dir: dossier de sortie
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # Sauvegarder la config
    config_path = os.path.join(output_dir, f"config_{run_id}.json")
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    # Cr√©er un fichier de m√©tadonn√©es
    meta_path = os.path.join(output_dir, f"meta_{run_id}.json")
    metadata = {
        'run_id': run_id,
        'timestamp': datetime.now().isoformat(),
        'fps_version': '1.3',
        'config_path': config_path,
        'system': {
            'N': config.get('system', {}).get('N'),
            'T': config.get('system', {}).get('T'),
            'mode': config.get('system', {}).get('mode'),
            'seed': config.get('system', {}).get('seed')
        }
    }
    
    with open(meta_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"üìù Configuration et m√©tadonn√©es sauvegard√©es pour {run_id}")


def log_end_of_run(run_id: str, summary: Optional[Dict] = None,
                   log_file: str = "runs_completed.txt") -> None:
    """
    Enregistre la fin d'un run avec r√©sum√© optionnel.
    
    Args:
        run_id: identifiant du run
        summary: r√©sum√© des r√©sultats
        log_file: fichier de log
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    with open(log_file, 'a') as f:
        f.write(f"\n[{timestamp}] Run termin√©: {run_id}\n")
        
        if summary:
            f.write(f"  R√©sum√©:\n")
            for key, value in summary.items():
                if isinstance(value, (int, float)):
                    f.write(f"    - {key}: {value:.4f}\n")
                else:
                    f.write(f"    - {key}: {value}\n")


# ============== SAUVEGARDE ET RESTAURATION ==============

def save_simulation_state(state: Dict[str, Any], checkpoint_path: str) -> None:
    """
    Sauvegarde l'√©tat complet de la simulation.
    
    Args:
        state: √©tat du syst√®me (strates, historique, etc.)
        checkpoint_path: chemin du checkpoint
    """
    os.makedirs(os.path.dirname(checkpoint_path) if os.path.dirname(checkpoint_path) else ".", 
                exist_ok=True)
    
    # Sauvegarder avec pickle (qui g√®re les types numpy)
    with open(checkpoint_path, 'wb') as f:
        pickle.dump(state, f, protocol=pickle.HIGHEST_PROTOCOL)
    
    # NE PAS cr√©er de version JSON qui cause des erreurs
    # On peut cr√©er juste un fichier d'info minimal
    info_path = checkpoint_path.replace('.pkl', '_info.txt')
    with open(info_path, 'w') as f:
        f.write(f"Checkpoint cr√©√© : {datetime.now().isoformat()}\n")
        f.write(f"Chemin : {checkpoint_path}\n")
        if 'strates' in state:
            f.write(f"Nombre de strates : {len(state.get('strates', []))}\n")
        if 't' in state:
            f.write(f"Temps actuel : {state.get('t', 0)}\n")
    
    print(f"üíæ √âtat sauvegard√©: {checkpoint_path}")


def load_simulation_state(checkpoint_path: str) -> Dict[str, Any]:
    """
    Charge un √©tat de simulation sauvegard√©.
    
    Args:
        checkpoint_path: chemin du checkpoint
    
    Returns:
        Dict: √©tat restaur√©
    """
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Checkpoint non trouv√©: {checkpoint_path}")
    
    with open(checkpoint_path, 'rb') as f:
        state = pickle.load(f)
    
    print(f"‚úÖ √âtat restaur√© depuis: {checkpoint_path}")
    return state


# ============== REPLAY ET ANALYSE ==============

def replay_from_logs(csv_path: str, start_t: float = 0, 
                     end_t: Optional[float] = None) -> Dict[str, np.ndarray]:
    """
    Rejoue une simulation depuis les logs CSV.
    
    Args:
        csv_path: chemin vers le fichier CSV
        start_t: temps de d√©but
        end_t: temps de fin (None = jusqu'√† la fin)
    
    Returns:
        Dict: donn√©es recharg√©es
    """
    print(f"üîÑ Replay depuis: {csv_path}")
    
    # Charger le CSV
    df = pd.read_csv(csv_path)
    
    # Filtrer par temps si n√©cessaire
    if 't' in df.columns:
        if end_t is not None:
            df = df[(df['t'] >= start_t) & (df['t'] <= end_t)]
        else:
            df = df[df['t'] >= start_t]
    
    # Convertir en dictionnaire de arrays
    data = {}
    for col in df.columns:
        if col != 'effort_status':  # Exclure les colonnes non num√©riques
            try:
                data[col] = df[col].values.astype(float)
            except:
                # Garder comme string si non num√©rique
                data[col] = df[col].values
    
    print(f"  ‚úì Charg√©: {len(df)} pas de temps, {len(data)} m√©triques")
    return data


def compare_runs(run1_path: str, run2_path: str, 
                 metrics: List[str]) -> Dict[str, Dict[str, float]]:
    """
    Compare deux runs sur des m√©triques sp√©cifiques.
    
    Args:
        run1_path: chemin du premier run
        run2_path: chemin du second run
        metrics: liste des m√©triques √† comparer
    
    Returns:
        Dict: comparaison des m√©triques
    """
    # Charger les donn√©es
    data1 = replay_from_logs(run1_path)
    data2 = replay_from_logs(run2_path)
    
    comparison = {}
    
    for metric in metrics:
        if metric in data1 and metric in data2:
            values1 = data1[metric]
            values2 = data2[metric]
            
            comparison[metric] = {
                'run1_mean': np.mean(values1),
                'run2_mean': np.mean(values2),
                'run1_std': np.std(values1),
                'run2_std': np.std(values2),
                'difference_mean': np.mean(values1) - np.mean(values2),
                'correlation': np.corrcoef(values1[:min(len(values1), len(values2))], 
                                          values2[:min(len(values1), len(values2))])[0, 1]
            }
    
    return comparison


# ============== EX√âCUTION PARALL√àLE ==============

def run_single_simulation(args: Tuple[str, Dict]) -> Dict[str, Any]:
    """
    Fonction worker pour ex√©cuter une simulation unique.
    
    Args:
        args: tuple (config_path, override_params)
    
    Returns:
        Dict: r√©sultats de la simulation
    """
    config_path, override_params = args
    
    try:
        # Importer les modules n√©cessaires
        import simulate
        import init
        
        # Charger la config
        config = init.load_config(config_path)
        
        # Appliquer les overrides
        for key, value in override_params.items():
            keys = key.split('.')
            target = config
            for k in keys[:-1]:
                target = target[k]
            target[keys[-1]] = value
        
        # Lancer la simulation
        result = simulate.run_simulation(config_path, config['system'].get('mode', 'FPS'))
        
        return {
            'status': 'success',
            'run_id': result['run_id'],
            'metrics': result['metrics']
        }
        
    except Exception as e:
        return {
            'status': 'error',
            'error': str(e),
            'traceback': traceback.format_exc()
        }


def batch_runner(configs_list: List[Union[str, Tuple[str, Dict]]], 
                 parallel: bool = True, n_workers: Optional[int] = None) -> List[Dict]:
    """
    Execute un batch de simulations en parall√®le ou s√©quentiellement.
    
    Args:
        configs_list: liste de configs ou tuples (config_path, overrides)
        parallel: ex√©cution parall√®le ou non
        n_workers: nombre de workers (None = nb de CPU)
    
    Returns:
        List[Dict]: r√©sultats de toutes les simulations
    """
    print(f"\nüöÄ Lancement batch: {len(configs_list)} simulations")
    
    # Normaliser les inputs
    normalized_configs = []
    for config in configs_list:
        if isinstance(config, str):
            normalized_configs.append((config, {}))
        else:
            normalized_configs.append(config)
    
    results = []
    
    if parallel:
        # Ex√©cution parall√®le
        n_workers = n_workers or cpu_count()
        print(f"  Mode parall√®le avec {n_workers} workers")
        
        with Pool(n_workers) as pool:
            results = pool.map(run_single_simulation, normalized_configs)
    else:
        # Ex√©cution s√©quentielle
        print("  Mode s√©quentiel")
        for config in normalized_configs:
            result = run_single_simulation(config)
            results.append(result)
            
            # Afficher le statut
            if result['status'] == 'success':
                print(f"  ‚úì {result['run_id']}")
            else:
                print(f"  ‚úó Erreur: {result['error']}")
    
    # R√©sum√©
    success_count = sum(1 for r in results if r['status'] == 'success')
    print(f"\nüìä Batch termin√©: {success_count}/{len(results)} succ√®s")
    
    return results


# ============== EXPORT DE DONN√âES ==============

def export_to_hdf5(data_dict: Dict[str, np.ndarray], hdf5_path: str) -> None:
    """
    Exporte des donn√©es volumineuses en format HDF5.
    
    Args:
        data_dict: dictionnaire de donn√©es √† exporter
        hdf5_path: chemin du fichier HDF5
    """
    if not HDF5_AVAILABLE:
        warnings.warn("HDF5 non disponible - export annul√©")
        return
    
    os.makedirs(os.path.dirname(hdf5_path) if os.path.dirname(hdf5_path) else ".", 
                exist_ok=True)
    
    with h5py.File(hdf5_path, 'w') as f:
        # M√©tadonn√©es
        f.attrs['created'] = datetime.now().isoformat()
        f.attrs['fps_version'] = '1.3'
        
        # Donn√©es
        for key, data in data_dict.items():
            if isinstance(data, np.ndarray):
                f.create_dataset(key, data=data, compression='gzip')
            elif isinstance(data, (list, tuple)):
                f.create_dataset(key, data=np.array(data), compression='gzip')
            else:
                # Convertir en array si possible
                try:
                    f.create_dataset(key, data=np.array([data]))
                except:
                    # Stocker comme attribut si non convertible
                    f.attrs[key] = str(data)
    
    # V√©rifier la taille
    file_size = os.path.getsize(hdf5_path) / (1024 * 1024)  # MB
    print(f"üíæ Export HDF5: {hdf5_path} ({file_size:.1f} MB)")


# ============== G√âN√âRATION D'IDENTIFIANTS ==============

def generate_run_id(prefix: str = "run") -> str:
    """
    G√©n√®re un identifiant unique pour un run.
    
    Args:
        prefix: pr√©fixe de l'identifiant
    
    Returns:
        str: identifiant unique
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Ajouter un hash court pour unicit√©
    random_bytes = os.urandom(4)
    hash_suffix = hashlib.md5(random_bytes).hexdigest()[:6]
    
    return f"{prefix}_{timestamp}_{hash_suffix}"


# ============== GESTION DES DOSSIERS ==============

def setup_directories(base_dir: str = "fps_output") -> Dict[str, str]:
    """
    Cr√©e la structure de dossiers pour les outputs FPS.
    
    Args:
        base_dir: dossier de base
    
    Returns:
        Dict: chemins cr√©√©s
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = os.path.join(base_dir, f"run_{timestamp}")
    
    directories = {
        'base': run_dir,
        'logs': os.path.join(run_dir, 'logs'),
        'checkpoints': os.path.join(run_dir, 'checkpoints'),
        'figures': os.path.join(run_dir, 'figures'),
        'reports': os.path.join(run_dir, 'reports'),
        'configs': os.path.join(run_dir, 'configs')
    }
    
    for dir_path in directories.values():
        os.makedirs(dir_path, exist_ok=True)
    
    print(f"üìÅ Structure cr√©√©e: {run_dir}")
    return directories


def archive_run(run_dir: str, archive_name: Optional[str] = None) -> str:
    """
    Archive un dossier de run complet.
    
    Args:
        run_dir: dossier √† archiver
        archive_name: nom de l'archive (auto-g√©n√©r√© si None)
    
    Returns:
        str: chemin de l'archive
    """
    if archive_name is None:
        archive_name = f"{os.path.basename(run_dir)}_archive"
    
    # Cr√©er l'archive
    archive_path = shutil.make_archive(
        archive_name,
        'zip',
        os.path.dirname(run_dir),
        os.path.basename(run_dir)
    )
    
    print(f"üì¶ Archive cr√©√©e: {archive_path}")
    return archive_path


# ============== CHECKSUM ET INT√âGRIT√â ==============

def compute_checksum(file_path: str, algorithm: str = 'sha256') -> str:
    """
    Calcule le checksum d'un fichier pour v√©rifier l'int√©grit√©.
    
    Args:
        file_path: chemin du fichier
        algorithm: algorithme de hash ('md5', 'sha256', etc.)
    
    Returns:
        str: checksum hexad√©cimal
    """
    hash_func = getattr(hashlib, algorithm)()
    
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_func.update(chunk)
    
    return hash_func.hexdigest()


def verify_data_integrity(data_dir: str, checksum_file: str = "checksums.txt") -> bool:
    """
    V√©rifie l'int√©grit√© des donn√©es d'un dossier.
    
    Args:
        data_dir: dossier contenant les donn√©es
        checksum_file: fichier de checksums
    
    Returns:
        bool: True si int√©grit√© v√©rifi√©e
    """
    checksum_path = os.path.join(data_dir, checksum_file)
    
    if not os.path.exists(checksum_path):
        print("‚ö†Ô∏è  Fichier de checksums non trouv√©")
        return False
    
    # Lire les checksums attendus
    expected_checksums = {}
    with open(checksum_path, 'r') as f:
        for line in f:
            if line.strip():
                parts = line.strip().split('  ')
                if len(parts) == 2:
                    expected_checksums[parts[1]] = parts[0]
    
    # V√©rifier chaque fichier
    all_valid = True
    for filename, expected in expected_checksums.items():
        file_path = os.path.join(data_dir, filename)
        if os.path.exists(file_path):
            actual = compute_checksum(file_path)
            if actual != expected:
                print(f"‚ùå Checksum invalide: {filename}")
                all_valid = False
            else:
                print(f"‚úì {filename}")
        else:
            print(f"‚ùå Fichier manquant: {filename}")
            all_valid = False
    
    return all_valid


# ============== GESTION DES ERREURS ==============

def handle_crash_recovery(state: Dict[str, Any], loggers: Dict,
                         exception: Exception) -> None:
    """
    G√®re la r√©cup√©ration apr√®s un crash.
    
    Args:
        state: √©tat du syst√®me au moment du crash
        loggers: informations de logging
        exception: exception lev√©e
    """
    crash_dir = "crash_recovery"
    os.makedirs(crash_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    crash_id = f"crash_{timestamp}"
    
    # Fonction helper pour convertir les types numpy
    def convert_numpy_to_python(obj):
        """Convertit r√©cursivement les types numpy en types Python natifs."""
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: convert_numpy_to_python(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy_to_python(item) for item in obj]
        else:
            return obj
    
    # Sauvegarder l'√©tat avec pickle (qui g√®re les types numpy)
    state_path = os.path.join(crash_dir, f"{crash_id}_state.pkl")
    try:
        save_simulation_state(state, state_path)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur sauvegarde √©tat pickle: {e}")
    
    # Convertir l'√©tat pour JSON
    state_for_json = convert_numpy_to_python(state)
    
    # Sauvegarder les d√©tails du crash
    crash_info = {
        'timestamp': timestamp,
        'run_id': loggers.get('run_id', 'unknown'),
        'exception_type': type(exception).__name__,
        'exception_message': str(exception),
        'traceback': traceback.format_exc(),
        't_current': float(state_for_json.get('t', 0)) if 't' in state_for_json else 'unknown',
        'n_strates': len(state_for_json.get('strates', [])),
        'mode': state_for_json.get('mode', 'unknown')
    }
    
    # Ajouter les m√©triques si disponibles
    if 'all_metrics' in state_for_json:
        crash_info['last_metrics'] = state_for_json['all_metrics']
    
    info_path = os.path.join(crash_dir, f"{crash_id}_info.json")
    try:
        with open(info_path, 'w') as f:
            json.dump(crash_info, f, indent=2)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur sauvegarde JSON: {e}")
        # Essayer sans les m√©triques
        crash_info.pop('last_metrics', None)
        with open(info_path, 'w') as f:
            json.dump(crash_info, f, indent=2)
    
    print(f"\nüö® Crash recovery:")
    print(f"  √âtat sauvegard√©: {state_path}")
    print(f"  Infos crash: {info_path}")
    print(f"  Pour reprendre: load_simulation_state('{state_path}')")


# ============== UTILITAIRES DIVERS ==============

def format_duration(seconds: float) -> str:
    """
    Formate une dur√©e en secondes en format lisible.
    
    Args:
        seconds: dur√©e en secondes
    
    Returns:
        str: dur√©e format√©e (ex: "2h 15m 30s")
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = seconds % 60
    
    parts = []
    if hours > 0:
        parts.append(f"{hours}h")
    if minutes > 0:
        parts.append(f"{minutes}m")
    if secs > 0 or len(parts) == 0:
        parts.append(f"{secs:.1f}s")
    
    return " ".join(parts)


def get_system_info() -> Dict[str, Any]:
    """
    R√©cup√®re des informations sur le syst√®me.
    
    Returns:
        Dict: informations syst√®me
    """
    import platform
    import psutil
    
    info = {
        'platform': platform.platform(),
        'python_version': platform.python_version(),
        'cpu_count': cpu_count(),
        'memory_total_gb': psutil.virtual_memory().total / (1024**3),
        'memory_available_gb': psutil.virtual_memory().available / (1024**3),
        'disk_usage_percent': psutil.disk_usage('/').percent
    }
    
    return info


# ============== TESTS ET VALIDATION ==============

if __name__ == "__main__":
    """
    Tests du module utils.py
    """
    print("=== Tests du module utils.py ===\n")
    
    # Test 1: G√©n√©ration d'ID
    print("Test 1 - G√©n√©ration d'identifiants:")
    for i in range(3):
        run_id = generate_run_id()
        print(f"  ID {i+1}: {run_id}")
    
    # Test 2: Gestion des dossiers
    print("\nTest 2 - Structure de dossiers:")
    dirs = setup_directories("test_fps_output")
    for key, path in dirs.items():
        print(f"  {key}: {path}")
    
    # Test 3: Sauvegarde de seed
    print("\nTest 3 - Log de seed:")
    test_seed = 42
    log_seed(test_seed, os.path.join(dirs['logs'], "seeds.txt"))
    print(f"  Seed {test_seed} logu√©e")
    
    # Test 4: Sauvegarde d'√©tat
    print("\nTest 4 - Sauvegarde/restauration d'√©tat:")
    test_state = {
        't': 50.0,
        'strates': [{'id': 0, 'An': 1.0}, {'id': 1, 'An': 0.8}],
        'history': [{'t': 0, 'S': 0}, {'t': 1, 'S': 0.5}]
    }
    
    checkpoint_path = os.path.join(dirs['checkpoints'], "test_checkpoint.pkl")
    save_simulation_state(test_state, checkpoint_path)
    
    restored_state = load_simulation_state(checkpoint_path)
    print(f"  √âtat restaur√©: t={restored_state['t']}, n_strates={len(restored_state['strates'])}")
    
    # Test 5: Configuration et m√©tadonn√©es
    print("\nTest 5 - Log de configuration:")
    test_config = {
        'system': {'N': 3, 'T': 100, 'mode': 'FPS', 'seed': 42},
        'strates': [{'A0': 1.0, 'f0': 1.0}] * 3
    }
    log_config_and_meta(test_config, "test_run", dirs['configs'])
    
    # Test 6: Checksum
    print("\nTest 6 - Checksum:")
    test_file = checkpoint_path
    checksum = compute_checksum(test_file)
    print(f"  SHA256: {checksum[:32]}...")
    
    # Test 7: Formatage de dur√©e
    print("\nTest 7 - Formatage de dur√©e:")
    durations = [45.3, 125.7, 3665.2, 7200.0]
    for d in durations:
        print(f"  {d}s ‚Üí {format_duration(d)}")
    
    # Test 8: Informations syst√®me
    print("\nTest 8 - Informations syst√®me:")
    try:
        sys_info = get_system_info()
        print(f"  Python: {sys_info['python_version']}")
        print(f"  CPUs: {sys_info['cpu_count']}")
        print(f"  RAM: {sys_info['memory_available_gb']:.1f}/{sys_info['memory_total_gb']:.1f} GB")
    except:
        print("  (psutil non disponible)")
    
    # Test 9: Archive
    print("\nTest 9 - Archivage:")
    archive_path = archive_run(dirs['base'])
    print(f"  Archive cr√©√©e: {archive_path}")
    
    # Nettoyage
    shutil.rmtree("test_fps_output", ignore_errors=True)
    if os.path.exists(archive_path):
        os.remove(archive_path)
    
    print("\n‚úÖ Module utils.py pr√™t √† orchestrer la symphonie FPS")
